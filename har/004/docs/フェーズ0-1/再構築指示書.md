# フェーズ0-1 再構築指示書（har/003）

フェーズ0-1をゼロからやり直すための決定事項を一枚に集約する。ここに書いた順で進めれば、har/003 を再構築し、フェーズ1のBLE方針に差し替え可能なHAR+U/S/CCSを得られる。

## 0. 前提とゴール
- ゴール: mHealth胸装着データで「そこそこマトモな HAR + U/S/CCS」を作り、フェーズ1 BLEポリシにそのまま差し替えられる状態にする。
- ゲート（test 平均）: 12クラス BAcc ≥0.80、4クラス BAcc ≥0.90（0.87–0.90 妥協）、ECE ≤0.05、Unknown率 5–15%、TinyML制約 Arena ≤80KB かつ t_inf ≤20ms@240MHz。
- データ源: `data/MHEALTHDATASET/`（胸装着）。Fs=50Hz。加速度 m/s^2、ジャイロ deg/s（使う場合）。

## 1. ディレクトリ構成（har/003）
```
har/003/
  configs/phase0-1.local.yaml
  data_processed/
  docs/フェーズ0-1/
    splits.yaml
    har_phase0-1_results.md
    再構築指示書.md
  models/
  runs/phase0-1/
  src/
    preprocess_mhealth.py
    model.py
    train_phase0-1.py
    calibrate_offline.py
    uscs_compute.py
    export_tflite.py
    export_c_header.py
```
※1ファイル=1責務を保つ。依存管理は har/004 で uv を使う（今後の発展用）。

## 2. データ仕様と前処理
- センサ: 胸 Acc 3ch を基準（6軸はオプション扱い）。
- 窓: 長さ2.0s（100点）、hop 1.0s（50%）、窓純度 ≥0.75。
- 境界除外: ±0.25s の中心部でラベル多数決、Null(0)窓は破棄。
- フィルタ: 0.4Hz 一階HPFで緩めの重力除去。
- 正規化: 被験者別 z-score（mean/stdはメタ保持可）。
- ラベル: 内部12で学習、推論時に運用4へ集約。

内部12→運用4マッピング:

| 内部12 | 運用4 |
| --- | --- |
| Sta/Wal/Jog/Run/Bik | Locomotion |
| UpS/DnS | Transition |
| Sit/Stan/Lie | Stationary |
| Tras/Null | Ignore |

- SHAログ（初回だけ実施し `SHA256.txt` を残す）:
```bash
find data/MHEALTHDATASET -type f -exec shasum -a 256 {} \; | sort > data/MHEALTHDATASET/SHA256.txt
```
- 出力仕様（`preprocess_mhealth.py`）: `har/003/data_processed/subjectXX.npz` に `X (N,T=100,C=3|6)`, `y12`, `y4`, `spans`, `preproc_hash`。窓純度は境界除外後の中心部で判定。

## 3. 分割（LOSO 5-fold）
- seed=42固定。val被験者は各foldでローテーション。
- `docs/フェーズ0-1/splits.yaml` に train/val/test を明記。例:
```yaml
folds:
  - id: fold1
    test: [1]
    val:  [2]
    train: [3,4,5,6,7,8,9,10]
  - id: fold2
    test: [3]
    val:  [4]
    train: [1,2,5,6,7,8,9,10]
  - id: fold3
    test: [5]
    val:  [6]
    train: [1,2,3,4,7,8,9,10]
  - id: fold4
    test: [7]
    val:  [8]
    train: [1,2,3,4,5,6,9,10]
  - id: fold5
    test: [9]
    val:  [10]
    train: [1,2,3,4,5,6,7,8]
```

## 4. モデル仕様（1D DS-CNN）
- 入力: [B, T=100, C=3]（6軸版は C=6 に差し替え）。
- 構成例: Conv1d( C→32, k=5 ) → DWConv32 k=5 → PWConv64 → DWConv64 k=5 → PWConv96 → GlobalAvgPool → Dense 96→12 → Softmax。
- 制約: パラメータ≲5k、FLOPs≲0.05M、演算は Conv/DWConv/ReLU/AvgPool/Softmax のみ（TFLM互換）。

## 5. 設定ファイル例（`configs/phase0-1.local.yaml`）
```yaml
paths:
  processed_dir: "har/003/data_processed"
  runs_dir: "har/003/runs/phase0-1"

training:
  device: "cpu"
  num_workers: 0

model:
  in_ch: 3
  n_classes: 12

train:
  batch: 256
  lr: 1.0e-3
  weight_decay: 1.0e-4
  max_epoch: 80
  early_stop_patience: 10
  use_class_weight: true

augment:
  time_stretch: {min: 0.9, max: 1.1}
  rot_deg: 5
  noise_snr_db: 20

calibration:
  ece_bins: 15
  ece_binning: "equal_frequency"
  temp_scale: true

unknown:
  tau_target_coverage: [0.05, 0.15]
  select_by: "max_F1_macro"

ccs:
  alpha: 0.6
  beta: 0.4
  theta_low: 0.40
  theta_high: 0.70
  min_stay_s: 2.0
  max_switch_per_s: 1
```

## 6. 学習手順（`train_phase0-1.py`）
- `WindowDataset(npz_paths)` で `X→float32 tensor`、`y12-1` を0–11に正規化。trainはshuffle=True、val/testはFalse。
- 1 epochごとに train→val を回し、val BAcc(12c)で best を更新。10epoch改善なしでearly stop、best stateで test 評価。
- 損失: クラス重み付きCrossEntropy（頻度逆数を正規化）。メトリクス: 12c/4cのBAccとF1をfoldごとに `metrics.json` 保存。fold集計を `summary.json` に mean/median/min/max で出力。

## 7. 校正（オフライン一括: `calibrate_offline.py`）
- 各foldの `metrics.json` から val logits/labels を収集し連結。
- グリッドで T_global を探索（例: 0.5–3.0）。softmax(logits/T)でECE最小のTを採用。
- T_global固定で確率を作り、max-softmaxの10%分位を τ_global（Unknown率10%の目安、要件5–15%内）。
- `global_calibration.json` に T_global, tau_global, target_unknown, ece_val, unknown_val を保存。
- test logitsに T_global/τ_global を適用し、`summary_calibrated.json` に 12c/4c BAcc/F1/ECE/Unknown を記録。ゲートを満たすか確認。

## 8. U/S/CCS 計算（`uscs_compute.py`）
- U: 正規化エントロピー `U=H(p)/log(K)`。conf=1−U。
- S: 10sスライド窓でラベル遷移回数 n_trans を数え、`S=1−min(1, n_trans/5)` を初期値。
- CCS: フェーズ0-1式 `CCS=0.6*U + 0.4*(1−S)`（Phase1式への差し替えポイントをコメントで明示）。
- 出力CSV: `t_start, t_end, y_true12, y_pred12, conf, U, S, CCS` を時系列で保存。

## 9. エクスポート（BLE接続を想定）
- `export_tflite.py`: PyTorch→TFLite。int8 PTQ（per-channel conv）。校正用にmHealth窓をランダム2000件使用。出力 `models/har003_phase0-1_int8.tflite`。
- `export_c_header.py`: TFLiteをC配列化し `har_model.h`、設定を `har_config.h` にまとめる（model_id, calib_T, tau_unknown, window_len, overlap, W_sec, theta_low/high を含める）。

## 10. ログとドキュメント
- `summary.json`/`summary_calibrated.json` に seed, split_id, preproc_hash, model_id, calib_T, tau_unknown, theta_low/high, 12c/4c BAcc/F1, ECE, Unknown率を必ず残す。
- `docs/フェーズ0-1/har_phase0-1_results.md` に目的/設定/モデル/結果/校正/U/S/CCS/TinyML export を簡潔に記載し、代表foldの図を添付（必要に応じて `results/` に画像・表を配置）。

## 11. 落とし穴と対処
- T/τ をfoldごとに最適化しない。T_global/τ_globalを一度決めて全foldへ適用。
- クラスウェイトは baselineを取ってから導入。重み過大で崩れたら均一CEへ戻す。
- 校正を満たさない状態でU/S/CCSを評価しない。まずECE≤0.05、Unknown率安定を優先。
- 崩れるfoldは診断レーン扱い。代表foldでexportと実験、問題foldは付録で分析。
- Phase1移行時はCCS式を差し替える計画をRunbook側に追記する。

## 12. 実行チェックリスト
- [ ] `SHA256.txt` 生成済みでデータ版を固定した。
- [ ] `splits.yaml` がLOSOローテーションになっている。
- [ ] `preprocess_mhealth.py` 出力の `preproc_hash` が記録されている。
- [ ] 学習/評価で12c・4cの指標と logits を `metrics.json` に保存した。
- [ ] `calibrate_offline.py` で T_global/τ_global を決定し、calibrated指標を確認した。
- [ ] U/S/CCS CSV と TinyML export (`.tflite`, `.h`) を生成した。
