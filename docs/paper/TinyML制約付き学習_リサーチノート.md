以下は、**TinyML環境（MCU）における制約付き強化学習／Multi‑armed Bandit実装**に関するリサーチノートです。  
イントロ的な一般論は省き、**MCU上で実際にどう実装するか／どこまでできているか**に関する深い部分だけを整理します。

---

# 1. TinyML向け学習の制約構造

- **二つの強い制約**
  - **ハードウェア制約**
    - RAM は数 KB〜数百 KB（例：STM32F103 20 KB, Nano 33 BLE 256 KB, Teensy 4.1 1 MB）。
    - Flash は 64 KB〜数 MB。コードと定数は置けるが、頻繁な書き換えには不向き。
    - 動的メモリ（`malloc/new`）は断片化リスクから避けるのが前提 → **静的配列／スタック確保が基本**。
    - FPU/DSP命令有無で実現可能なアルゴリズムが変わる（Cortex‑M3 と M4F/M7 の差は大きい）。
  - **安全・QoS制約**
    - LoRaWAN デューティサイクル、規制上限（1%）などを**絶対に越えられない**。
    - 医療系やインフラ監視では「試行錯誤の失敗」が人命・法令違反に直結 → 無制限探索不可。
- **結論として必要なアーキテクチャ**
  - 学習アルゴリズムそのものは「通常の」報酬最適化に徹し、
  - その外側に **軽量な Safety Filter（Action Masking / CBF など）** を置いてハード制約を担保する構造が現実解として採用されている。

---

# 2. MCU上の Multi‑armed Bandit / LinUCB 実装

## 2.1 単純 MAB（ε‑Greedy, UCB1）

- **特徴**
  - 必要状態は「各アームの平均報酬」「訪問回数」だけ → メモリ O(K)。
  - 8‑bit MCU でも実装可能（tabular Q‑learning と同程度）。
- **限界**
  - コンテキスト（SNR, バッテリ, 位置など）を考慮できないため、通信制御などの実用シナリオでは表現力不足。

---

## 2.2 線形コンテキストバンディット（LinUCB）

- **モデル**
  - 各アーム a の期待報酬：`E[r | x_a] = x_a^T θ*`（x_a∈ℝ^d）。
  - 推定量：`θ_hat = A^-1 b`  
    - `A = Σ x x^T + λI`、`b = Σ r x`。
  - UCB スコア：`score(a) = x_a^T θ_hat + α sqrt(x_a^T A^-1 x_a)`。

- **MCU上の最大のボトルネック**
  - d×d 行列 A とその逆行列 A^-1 を保持・更新する必要がある。
  - 朴素な逆行列計算は O(d^3) → 数十 MHz クラスMCUには重い。

---

## 2.3 Sherman–Morrison 公式による高速化

- **ランク1更新**
  - 新サンプル (x_t, r_t) に対し、`A_{t+1} = A_t + x_t x_t^T`。
  - Sherman‑Morrison により、

    ```text
    A_{t+1}^{-1}
      = A_t^{-1} - (A_t^{-1} x_t x_t^T A_t^{-1}) / (1 + x_t^T A_t^{-1} x_t)
    ```

  - 必要な計算は
    - ベクトル v = A_t^-1 x_t（O(d^2)）
    - スカラー s = 1 + x_t^T v（O(d)）
    - A^-1 のランク1更新（O(d^2)）
  - → **1ステップあたり O(d^2)** に削減（O(d^3)→O(d^2)）。

- **実装上の工夫（C/C++）**
  - 行列は `float A_inv[d*d]` の 1次元配列に格納（SIMD／キャッシュ友好）。
  - 中間ベクトル `v[d]` などはクラスメンバとして **静的確保**（ヒープ不使用）。
  - 対称性（A^-1 は対称）を活かした上三角のみの格納も理論上は可能だが、
    - index計算が複雑化し、SIMD化が難しくなるため、
    - 多くの実装では「フル行列＋SIMD」の方を採用。

- **報告されている性能**
  - Cortex‑M4（STM32 Nucleo）上の最適化版 LinUCB:
    - d=16 の場合、朴素版 ≈ 5 ms/step → Woodbury＋SIMD で ≈ 0.3 ms/step に短縮（約1/15）。
  - RAM 使用量は d=16, K≲30 の設定で **1 KBオーダー** に収まる。

---

## 2.4 プラットフォーム適合性（抜粋）

- **20 KB RAM級（STM32F103など）**
  - 可能：Tabular Q‑learning, ε‑Greedy/UCB1, **ごく小さい d（≤4）** の LinUCB。
  - 限界：d が少し増えると A/A^-1 で RAM を使い切る。
- **256 KB RAM級（Arduino Nano 33 BLE, Cortex‑M4F）**
  - 可能：d≲16 の LinUCB、軽量 DNN を用いた Deep RL（小規模）。
  - FPU + DSP 命令あり → CMSIS‑DSP で行列演算高速化。
- **1 MB RAM級（Teensy 4.1, Cortex‑M7）**
  - 可能：d≳32 の LinUCB、PPO/SAC 等の Deep RL 学習も（RLtools 利用前提）。
- **ESP32**
  - RAM ≈ 520 KB、Flash ≈ 4 MB。
  - Wi‑Fi/BLE 内蔵のため、**Federated Learning や Multi‑agent Bandit** の通信基盤として有利。

---

# 3. 安全性制約の実装メカニズム

## 3.1 アクションマスキング（Validity Masking）

- **考え方**
  - 状態 s_t で「絶対に取ってはいけない行動 a」を、
    - 学習アルゴリズムの**外側で**除外し、
    - バンディット／RL側には「選べるアーム集合 A_valid」だけを渡す。
  - → 学習中も**ハード制約を破らない**。

- **LoRaWAN デューティサイクル例**
  - 制約：サブギガ帯で **Duty ≤ 1%**。
  - 各アーム a = (SF, TxPower) について、Time‑on‑Air `T_air(a)` を LoRaWAN 仕様から算出。
  - 直近履歴から「累積 ToA」と「回復までの残り」を計算し、
    - `current_ToA + T_air(a) > budget` なら a を INVALID に設定。
  - LinUCB/UCB1/Thompson 等は、A_valid からのみアクションを選ぶ。
  - 数理的には「Volatile Bandit（可用アーム集合が時間変動）」として扱われる。

---

## 3.2 Control Barrier Functions（CBF）の簡略フィルタ

- **用途**
  - 慣性のある系（ロボット・ドローン等）で、**「その行動を選んだ瞬間はOKだが、その後のダイナミクスで衝突する」**ケースを防ぐ。
- **理論（概念レベル）**
  - 安全集合 h(x)≥0 に対し、

    ```text
    d/dt h(x) + α h(x) ≥ 0 を満たす u のみ許容
    ```

- **MCU向け簡略実装**
  - バリア条件をそのままQPで解くのではなく、
    - 状態 x と提案行動 u_nominal に対して「危険かどうか」を安価に判定し、
    - 危険なら `u_safe` に置き換える**関数として実装**する。
  - C++イメージ:

    ```cpp
    float safety_filter(float u_nominal, const State& x) {
        if (is_violation_likely(x, u_nominal)) {
            return calculate_safe_u(x); // 速度/位置制限など
        }
        return u_nominal;
    }
    ```

  - 学習アルゴリズムは、この `u_safe` とその結果の報酬を観測するため、
    - 結果的に「安全領域内での最適方策」を学ぶことになる。

---

# 4. ケーススタディ：LoRaWAN ADR用 LinUCB（制約付き）

## 4.1 問題設定

- **目的**
  - LoRaWAN エンドデバイスで、
    - PDR を維持しつつ、
    - 消費エネルギー（送信電力＋ToA）を最小化。
- **変数**
  - コンテキスト x_t（例）:
    - 直近 N 回の SNR の平均／分散。
    - 直近の成功/失敗フラグ。
    - バッテリ残量。
  - アーム a:
    - SF ∈ {7,…,12} × TxPower ∈ {2,…,14 dBm} → K≈30。
  - 報酬 r_t（例）:

    ```text
    r_t = α * (PDR_t / PDR_target) - (1-α) * (Energy_t / Energy_max)
    ```

- **制約**
  - 法定 Duty ≤ 1% → **Action Masking** で保証。

---

## 4.2 MCU実装

- **ターゲット**
  - STM32L0 クラス（RAM ≈ 20 KB, 超低消費電力）。
- **状態保持**
  - d=4 とすると、
    - A_inv: 4×4 float = 64 bytes。
    - θ: 4 float = 16 bytes。
    - 各アームの平均報酬・選択回数：数百バイト。
  - 全体で **1 KB 未満** に収まる構成が可能。

- **動作イメージ**
  - 各送信結果ごとに LinUCB 更新（Sherman‑Morrison）。
  - 次の送信タイミングで、Action Masking されたアーム集合から UCB 最大のアームを選択。

- **報告されている効果**
  - シミュレーション／実機評価では、
    - 標準 ADR と比較して、**エネルギー効率 15–30% 改善**。
    - PDR は同等か、それ以上を維持。
  - 混雑環境でも「SF 上げすぎによるネットワーク崩壊」を避けられるケースが報告されている。

---

# 5. ケーススタディ：ECG サンプリングレート制御（TinyRL）

## 5.1 問題設定

- **用途**
  - 不整脈検知用 ECG ウェアラブル。
  - 常時 500 Hz サンプリングはバッテリ的に非現実的。
- **目的**
  - 不整脈検知精度 ≈99% を維持しつつ、
  - 平均消費電力をできるだけ下げる。

---

## 5.2 RLtools を用いた DQN Lite

- **構成**
  - MCU: Arduino Nano 33 BLE (Cortex‑M4F, 256 KB RAM)。
  - 特徴量: R‑R 間隔、QRS 幅などの軽量特徴から状態ベクトル s_t（4次元程度）を作成。
  - アクション:
    - {低レート, 中レート, 高レート} = {125 Hz, 250 Hz, 500 Hz}。
  - Policy/Qネットワーク（RLtools）:
    - 4 → 16 → 3 の全結合ネットワーク（ReLU）。
    - パラメータ数 = (4×16+16) + (16×3+3) = 131。
    - 単精度 float でも重みだけで ≈524 バイト + 中間バッファ含めても数 KB 程度。

- **学習の運用パターン**
  - 日中: 推論のみ（学習オフ）、報酬候補となるイベントをログに蓄積。
  - 夜間充電中 or 定期タイミング: ログを用いてバッチ学習（オンデバイス）／または Replay Buffer を用いたオンライン学習。
  - RLtools により、同じ C++ コードを PC シミュレータ＋MCU の両方で実行できるため、
    - まず PC 上でハイパラを詰めてから MCU に移植、というワークフローが取られている。

- **報告されている効果**
  - 常時 500 Hz サンプリングと比較して、
    - 不整脈検知精度 ≈99% を維持しつつ、
    - **平均消費電力 ≈1/7** まで削減。
  - 直前数十秒の HRV や `S_conf` の揺らぎが大きくなると高レートを選び、
    - 安定期は低レートに落とすポリシーを自律的に獲得。

---

# 6. 実装ベストプラクティス（TinyML学習用）

- **静的割り当ての徹底**
  - `std::vector`, `std::map` は基本的に使わない。
  - RLtools / ETL などの静的コンテナ、もしくは生配列を用いてヒープをゼロにする。
  - リンカの `.map` を確認し、`.bss/.data` サイズとスタックマージンを常に把握する。

- **PCシミュレーション→MCU移植**
  - 同じ C++ コードを
    - PC（Linux/macOS）でシミュレーション（OpenAI Gym 等）、
    - その後クロスコンパイルして MCU 上で動かす、
  - という 2段階開発が、TinyRL では実用的に採用されている。

- **数値精度と FPU の扱い**
  - FPUなし（Cortex‑M3 等）では float はソフトウェア実装 → 可能なら M4F 以上を使う。
  - LinUCB の A^-1 更新など、数値安定性が重要な部分は float（単精度）が最低ライン。
  - 固定小数点化は可能だが、実装・検証コストが高いため、まずは FPU 付きMCU＋float が現実解。

---

本ノートは、TinyML 環境において **「どの程度までバンディット/RLが現実的か」** を判断するための材料として、実装レベルの情報と具体的な削減効果のみを抜き出している。  
フェーズ2以降の MAB/Safe‑MAB 設計時には、ここに挙げた LinUCB 最適化・Action Masking・簡易CBF・RLtools のパターンを必要に応じて流用する。 

